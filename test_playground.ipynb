{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Activations import *\n",
    "from Layer import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mnist_train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "X = df.iloc[:,1:].values\n",
    "Y = df.iloc[:,0].values\n",
    "labels = list(set(Y))\n",
    "\n",
    "def one_hot(s):\n",
    "  out = np.ones(len(labels))\n",
    "  out[s] = 1\n",
    "  return out\n",
    "\n",
    "mean, std = np.mean(X), np.std(X)\n",
    "\n",
    "normalize = lambda x : (x-mean)/std\n",
    "reshape = lambda z: z.reshape((28,28))\n",
    "process = lambda x : reshape(normalize(x))\n",
    "\n",
    "\n",
    "x_train = np.array(list(map(process, X)))\n",
    "y_train = np.array(list(map(one_hot, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Activations import *\n",
    "\n",
    "def conv(img, ker,bias, s=1):\n",
    "  (k_h, k_w) = ker.shape # filter dimensions\n",
    "  im_h, im_w = img.shape # image dimensions\n",
    "\n",
    "  out_dim = int((im_h - k_h)/s)+1\n",
    "\n",
    "\n",
    "  out = np.zeros((out_dim,out_dim))\n",
    "\n",
    "  curr_y = out_y = 0\n",
    "  while curr_y + k_h <= im_h:\n",
    "    curr_x = out_x = 0\n",
    "    while curr_x + k_w <= im_w:\n",
    "      out[out_y, out_x] = np.sum(ker * img[curr_y:curr_y+k_h, curr_x:curr_x+k_w])+bias\n",
    "      curr_x += s\n",
    "      out_x += 1\n",
    "    curr_y += s\n",
    "    out_y += 1\n",
    "  return out\n",
    "\n",
    "def maxpool(X, k, s=2):\n",
    "  x_h, x_w = X.shape\n",
    "  \n",
    "  out_dim = int((x_h-k)/s)+1\n",
    "  out = np.zeros((out_dim, out_dim))\n",
    "\n",
    "  curr_y = out_y = 0\n",
    "  while curr_y +k <= x_h:\n",
    "    curr_x=out_x = 0\n",
    "    while curr_x <= k <= x_w:\n",
    "      out[out_y, out_x] = np.max(X[curr_y:curr_y+k, curr_x:curr_x+k])\n",
    "      curr_x += s\n",
    "      out_x += 1\n",
    "    curr_y += s\n",
    "    out_y += 1\n",
    "  return out\n",
    "\n",
    "class ConvLayer():\n",
    "    \n",
    "    def __init__(self, input_dim, output_c, kernel_size, activation):\n",
    "        self.kernels = np.random.random((output_c, kernel_size, kernel_size))\n",
    "        self.biases = np.random.random((output_c))\n",
    "    \n",
    "        self.input_dim = input_dim\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "        self.output_c = output_c\n",
    "        self.activation = activation_dict[activation][0]\n",
    "        self.activation_grad = activation_dict[activation][1]\n",
    "\n",
    "    def conv(self, z):\n",
    "    \n",
    "        out = []\n",
    "        for k, ker in enumerate(self.kernels):\n",
    "            out.append(conv(z, ker, self.biases[k]))\n",
    "        return np.array(out)\n",
    "\n",
    "    def activate(self, z):\n",
    "        return self.activation(z)\n",
    "    \n",
    "    def downsample(self, z):\n",
    "        out = []\n",
    "        for i,x in enumerate(z):\n",
    "            out.append(maxpool(x,self.kernel_size))\n",
    "        return np.array(out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.activate(self.conv(x))\n",
    "        return self.downsample(z)\n",
    "\n",
    "    #this returns the flattened feature map to feed into a fully connected layer\n",
    "    def flatten(self, z):\n",
    "        return z.reshape((z.size,1)) \n",
    "\n",
    "    def convolutionBackward(self, dconv_prev, conv_in, s=1):\n",
    "        '''\n",
    "        Backpropagation through a convolutional layer. \n",
    "        '''\n",
    "        filt = self.kernels\n",
    "        (n_f, n_c, f, _) = filt.shape\n",
    "        (_, orig_dim, _) = conv_in.shape\n",
    "        \n",
    "        ## initialize derivatives\n",
    "        dout = np.zeros(conv_in.shape) \n",
    "        dfilt = np.zeros(filt.shape)\n",
    "        dbias = np.zeros((n_f,1))\n",
    "        for curr_f in range(n_f):\n",
    "            # loop through all filters\n",
    "            curr_y = out_y = 0\n",
    "            while curr_y + f <= orig_dim:\n",
    "                curr_x = out_x = 0\n",
    "                while curr_x + f <= orig_dim:\n",
    "                    # loss gradient of filter (used to update the filter)\n",
    "                    dfilt[curr_f] += dconv_prev[curr_f, out_y, out_x] * conv_in[:, curr_y:curr_y+f, curr_x:curr_x+f]\n",
    "                    # loss gradient of the input to the convolution operation (conv1 in the case of this network)\n",
    "                    dout[:, curr_y:curr_y+f, curr_x:curr_x+f] += dconv_prev[curr_f, out_y, out_x] * filt[curr_f] \n",
    "                    curr_x += s\n",
    "                    out_x += 1\n",
    "                curr_y += s\n",
    "                out_y += 1\n",
    "            # loss gradient of the bias\n",
    "            dbias[curr_f] = np.sum(dconv_prev[curr_f])\n",
    "    \n",
    "        return dout, dfilt, dbias\n",
    "\n",
    "    def nanargmax(arr):\n",
    "        '''\n",
    "        return index of the largest non-nan value in the array. Output is an ordered pair tuple\n",
    "        '''\n",
    "        idx = np.nanargmax(arr)\n",
    "        idxs = np.unravel_index(idx, arr.shape)\n",
    "        return idxs \n",
    "\n",
    "    def maxpoolBackward(dpool, orig, f, s=1):\n",
    "        '''\n",
    "        Backpropagation through a maxpooling layer. The gradients are passed through the indices of greatest value in the original maxpooling during the forward step.\n",
    "        '''\n",
    "        (n_c, orig_dim, _) = orig.shape\n",
    "    \n",
    "        dout = np.zeros(orig.shape)\n",
    "    \n",
    "        for curr_c in range(n_c):\n",
    "            curr_y = out_y = 0\n",
    "            while curr_y + f <= orig_dim:\n",
    "                curr_x = out_x = 0\n",
    "                while curr_x + f <= orig_dim:\n",
    "                    # obtain index of largest value in input for current window\n",
    "                    (a, b) = nanargmax(orig[curr_c, curr_y:curr_y+f, curr_x:curr_x+f])\n",
    "                    dout[curr_c, curr_y+a, curr_x+b] = dpool[curr_c, out_y, out_x]\n",
    "                \n",
    "                    curr_x += s\n",
    "                    out_x += 1\n",
    "                curr_y += s\n",
    "                out_y += 1\n",
    "        \n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = ConvLayer(3, 16, 3, 'relu')\n",
    "x = np.random.random((50, 50))\n",
    "z = F1.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1.convolutionBackward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
